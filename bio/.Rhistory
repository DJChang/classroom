sweep(x, 2, xm, "-")
xm = apply(x,2,mean)
xv = apply(x,2,sd)
sweep(x, 2, xm, "-")
### logistic regression
x = biodata[,-1]
y = biodata[,1]
xm = apply(x,2,mean)
xm
xv = apply(x,2,sd)
x = sweep(x, 2, xm, "-")
x = sweep(x, 2, xm, "-")
x
x = sweep(x, 2, xv, "/")
x
colMeans(x)
### logistic regression
x = biodata[,-1]
y = biodata[,1]
xm = apply(x,2,mean)
xv = apply(x,2,sd)
x = sweep(x, 1, xm, "-")
x = sweep(x, 2, xm, "-")
xm
x
colMeans(x)
### logistic regression
x = biodata[,-1]
apply(x,2,mean)
xm
sweep(x, 2, xm, "-")
colMeans(sweep(x, 2, xm, "-"))
x = sweep(x, 2, xm, "-")
colMeans(x)
x = sweep(x, 2, xv, "/")
colMeans(x)
x = biodata[,-1]
y = biodata[,1]
xm = apply(x,2,mean)
xv = apply(x,2,sd)
x = sweep(x, 2, xm, "-")
x = sweep(x, 2, xv, "/")
apply(x,2,mean)
apply(x,2,sd)
cdata = cbind(y,x)
cdata = as.data.frame(cbind(y,x))
names(cdata) = names(biodata)
# full model
fit_full=glm(diagnosis~.,  data = cdata, family = binomial())
barplot(fit_full$coefficients, las = 2)
cdata
colMeans(cdata)
cdata
colMeans(cdata[,-1])
# full model
fit_full=glm(diagnosis~.,  data = cdata, family = binomial())
barplot(fit_full$coefficients, las = 2)
# AIC
AIC(fit_full)
# BIC
BIC(fit_full)
# the simplest model
fit_init =glm(diagnosis~1,
data = biodata, family = binomial())
BIC(fit_init)
# the simplest model
fit_init =glm(diagnosis~1,
data = cdata, family = binomial())
BIC(fit_init)
# forward selection
model_s = step(fit_init,
scope=list(lower=formula(fit_init),
upper=formula(fit_full)),
direction = 'forward')
summary(model_s)
BIC(model_s)
# glmnet
x = as.matrix(cdata[,-1])
class(x)
y =cdata$diagnosis
fit <- glmnet(x, y, family = "binomial", standardize = T)
plot(fit)
# model selection by cv
fit_cv = cv.glmnet(x,as.integer(y), nfold = 5)
plot(fit_cv)
fit_cv$lambda
i = which.min(fit_cv$cvm)
fit <- glmnet(x, y, family = "binomial",
lambda = fit_cv$lambda[i])
barplot(as.numeric(fit$beta))
barplot(as.numeric(fit$beta), names = names(cdata)[-1])
barplot(as.numeric(fit$beta),
names = names(cdata)[-1],
las = 2)
deviance(fit) + 2*fit$df
2*log(n)*fit$df
log(n)*fit$df
deviance(fit) + log(n)*fit$df
deviance(fit) + log(n)*fit$df
BIC(model_s)
deviance(fit) + log(n)*fit$df
fit_re <- glmnet(x, y, family = "binomial",
lambda = fit_cv$lambda[i])
barplot(as.numeric(fit_re$beta),
names = names(cdata)[-1],
las = 2)
# glmnet
x = as.matrix(cdata[,-1])
class(x)
y =cdata$diagnosis
fit <- glmnet(x, y, family = "binomial", standardize = T)
plot(fit)
# model selection by BIC
fit$df
# model selection by BIC
fit$dim
# model selection by BIC
fit$dim[2]
fit$beta[1,]
fit$beta[,1]
deviance
?predict.glmnet
predict(fit)
predict(fit, x)
# model selection by BIC
pred = predict(fit, x)
pred
pred[,1]
xb = pred[,1]
- y*xb  + log( 1 + exp(xb))
y
as.integer(cdata$diagnosis)-1
x = as.matrix(cdata[,-1])
class(x)
y = as.integer(cdata$diagnosis)-1
fit <- glmnet(x, y, family = "binomial", standardize = T)
plot(fit)
# model selection by cv
fit_cv = cv.glmnet(x,as.integer(y), nfold = 5)
plot(fit_cv)
fit_cv$lambda
i = which.min(fit_cv$cvm)
fit_re <- glmnet(x, y, family = "binomial",
lambda = fit_cv$lambda[i])
barplot(as.numeric(fit_re$beta),
names = names(cdata)[-1],
las = 2)
barplot(as.numeric(fit_re$beta),
names = names(cdata)[-1],
las = 2)
# model selection by BIC
pred = predict(fit, x)
xb = pred[,1]
-y*xb  + log( 1 + exp(xb))
xb = pred[,1]
# model selection by BIC
pred = predict(fit, x)
xb
-y*xb  + log( 1 + exp(xb))
2*sum(-y*xb  + log( 1 + exp(xb)))
sum(-y*xb  + log( 1 + exp(xb))
)
sum(y*xb  - log( 1 + exp(xb))
}
deviance(fit) + log(n)*fit$df
sum(y*xb  - log( 1 + exp(xb)))
loglik = sum(y*xb  - log( 1 + exp(xb)))
fit$df[1]
n
n = nrow(x)
n
v = c()
pred = predict(fit, x)
n = nrow(x)
v = c()
for ( i in 1:fit$dim[2])
{
xb = pred[,1]
loglik = sum(y*xb  - log( 1 + exp(xb)))
v[i] = -2*loglik + log(n)*fit$df[1]
}
plot(v)
pred = predict(fit, x)
n = nrow(x)
v = c()
for ( i in 1:fit$dim[2])
{
xb = pred[,i]
loglik = sum(y*xb  - log( 1 + exp(xb)))
v[i] = -2*loglik + log(n)*fit$df[i]
}
plot(v)
which.min(v)
which.min
which.min(v)
fit$beta
fit$beta[,47]
fit$beta[,which.min(v)]
barplot(fit$beta[,which.min(v)],las = 2 )
fit$df[which.min(v)]
fit$df[which.min(v)]
barplot(fit$beta[,which.min(v)],las = 2 )
min(v)
BIC(model_s)
rm(list = ls())
gc()
setwd("~/GitHub/classroom/bio")
biodata = read.csv("./data/data.csv")
str(biodata)
table(biodata$id)
biodata$X <- NULL
str(biodata)
table(biodata$diagnosis)
id = biodata[,1]
biodata = biodata[,-1]
summary(biodata[,-1])[3,]
m1 = apply(biodata[,-1], 2, FUN = mean)
m2 = apply(biodata[,-1], 2, FUN = sd)
# fig
barplot(m1)
barplot(m2)
library(dplyr)
btable = biodata %>% group_by(diagnosis) %>%
summarise_all(.funs = list(mean,sd))
View(t(btable))
idx = biodata$diagnosis=="M"
m = biodata[,-1]
j = 1
r  = c()
for (j in 1:ncol(m))
{
fit = t.test(m[idx,j], m[!idx,j])
r[j] = fit$p.value
}
names(r) = names(m)
par(mai = c(2.5,1,1,1))
barplot(r, las = 2)
library(corrplot)
corrmat_full= cor(biodata[,-(1:2)])
corrplot(corrmat_full, method="circle")
corrmat_B= cor(biodata[biodata$diagnosis == "B",-(1:2)])
corrplot(corrmat_B, method="circle")
corrmat_M= cor(biodata[biodata$diagnosis == "M",-(1:2)])
corrplot(corrmat_M, method="circle")
### logistic regression
x = biodata[,-1]
y = biodata[,1]
xm = apply(x,2,mean)
xv = apply(x,2,sd)
x = sweep(x, 2, xm, "-")
x = sweep(x, 2, xv, "/")
cdata = as.data.frame(cbind(y,x))
names(cdata) = names(biodata)
library(MASS)
# full model
fit_full=glm(diagnosis~.,  data = cdata, family = binomial())
barplot(fit_full$coefficients, las = 2)
# AIC
AIC(fit_full)
# BIC
BIC(fit_full)
# the simplest model
fit_init =glm(diagnosis~1,
data = cdata, family = binomial())
AIC(fit_init)
# forward selection
model_s = step(fit_init,
scope=list(lower=formula(fit_init),
upper=formula(fit_full)),
direction = 'forward')
summary(model_s)
AIC(model_s)
# glmnet
x = as.matrix(cdata[,-1])
class(x)
y = as.integer(cdata$diagnosis)-1
fit <- glmnet(x, y, family = "binomial", standardize = T)
plot(fit)
# model selection by cv
fit_cv = cv.glmnet(x,as.integer(y), nfold = 5)
plot(fit_cv)
fit_cv$lambda
i = which.min(fit_cv$cvm)
fit_re <- glmnet(x, y, family = "binomial",
lambda = fit_cv$lambda[i])
barplot(as.numeric(fit_re$beta),
names = names(cdata)[-1],
las = 2)
# model selection by BIC
pred = predict(fit, x)
n = nrow(x)
v = c()
for ( i in 1:fit$dim[2])
{
xb = pred[,i]
loglik = sum(y*xb  - log( 1 + exp(xb)))
v[i] = -2*loglik + 2*fit$df[i]
}
fit$df[which.min(v)]
barplot(fit$beta[,which.min(v)],las = 2 )
min(v)
n
trunc(n*0.7)
idx = sample(1:n, trunc(n*0.7))
idx
cdata.tr = cdata[idx,]
cdata.te = cdata[!idx,]
cdata.tr
# the simplest model
fit_init =glm(diagnosis~1,
data = cdata.tr, family = binomial())
AIC(fit_init)
fit_full =glm(diagnosis~.,
data = cdata.tr, family = binomial())
model_s = step(fit_init,
scope=list(lower=formula(fit_init),
upper=formula(fit_full)),
direction = 'forward')
summary(model_s)
predict(model_s,cdata.te)
cdata.te
idx
cdata.te = cdata[-idx,]
predict(model_s, cdata.te)
?predict.glm
predict(model_s, cdata.te, type = 'response')
pred = predict(model_s, cdata.te, type = 'response')
pred>0.5
as.integer(pred>0.5)
cdata.te$diagnosis
y
cdata
rm(list = ls())
gc()
setwd("~/GitHub/classroom/bio")
biodata = read.csv("./data/data.csv")
str(biodata)
table(biodata$id)
biodata$X <- NULL
str(biodata)
table(biodata$diagnosis)
id = biodata[,1]
biodata = biodata[,-1]
summary(biodata[,-1])[3,]
m1 = apply(biodata[,-1], 2, FUN = mean)
m2 = apply(biodata[,-1], 2, FUN = sd)
# fig
barplot(m1)
barplot(m2)
library(dplyr)
btable = biodata %>% group_by(diagnosis) %>%
summarise_all(.funs = list(mean,sd))
View(t(btable))
idx = biodata$diagnosis=="M"
m = biodata[,-1]
j = 1
r  = c()
for (j in 1:ncol(m))
{
fit = t.test(m[idx,j], m[!idx,j])
r[j] = fit$p.value
}
names(r) = names(m)
par(mai = c(2.5,1,1,1))
barplot(r, las = 2)
library(corrplot)
corrmat_full= cor(biodata[,-(1:2)])
corrplot(corrmat_full, method="circle")
corrmat_B= cor(biodata[biodata$diagnosis == "B",-(1:2)])
corrplot(corrmat_B, method="circle")
corrmat_M= cor(biodata[biodata$diagnosis == "M",-(1:2)])
corrplot(corrmat_M, method="circle")
### logistic regression
x = biodata[,-1]
y = as.integer(biodata[,1])-1
xm = apply(x,2,mean)
xv = apply(x,2,sd)
x = sweep(x, 2, xm, "-")
x = sweep(x, 2, xv, "/")
cdata = as.data.frame(cbind(y,x))
names(cdata) = names(biodata)
names(cdata) = names(biodata)
library(MASS)
# full model
fit_full=glm(diagnosis~.,  data = cdata, family = binomial())
barplot(fit_full$coefficients, las = 2)
# AIC
AIC(fit_full)
# BIC
BIC(fit_full)
# the simplest model
fit_init =glm(diagnosis~1,
data = cdata, family = binomial())
AIC(fit_init)
# forward selection
model_s = step(fit_init,
scope=list(lower=formula(fit_init),
upper=formula(fit_full)),
direction = 'forward')
summary(model_s)
AIC(model_s)
# glmnet
x = as.matrix(cdata[,-1])
class(x)
y = as.integer(cdata$diagnosis)
fit <- glmnet(x, y, family = "binomial", standardize = T)
plot(fit)
# model selection by cv
fit_cv = cv.glmnet(x,as.integer(y), nfold = 5)
plot(fit_cv)
fit_cv$lambda
i = which.min(fit_cv$cvm)
fit_re <- glmnet(x, y, family = "binomial",
lambda = fit_cv$lambda[i])
barplot(as.numeric(fit_re$beta),
names = names(cdata)[-1],
las = 2)
# model selection by BIC
pred = predict(fit, x)
n = nrow(x)
v = c()
for ( i in 1:fit$dim[2])
{
xb = pred[,i]
loglik = sum(y*xb  - log( 1 + exp(xb)))
v[i] = -2*loglik + 2*fit$df[i]
}
fit$df[which.min(v)]
barplot(fit$beta[,which.min(v)],las = 2 )
min(v)
idx = sample(1:n, trunc(n*0.7))
cdata.tr = cdata[idx,]
cdata.te = cdata[-idx,]
# the simplest model
fit_init =glm(diagnosis~1,
data = cdata.tr, family = binomial())
fit_full =glm(diagnosis~.,
data = cdata.tr, family = binomial())
model_s = step(fit_init,
scope=list(lower=formula(fit_init),
upper=formula(fit_full)),
direction = 'forward')
pred = predict(model_s, cdata.te, type = 'response')
as.integer(pred>0.5)
as.integer(pred>0.5)  == cdata.te$diagnosis
mean(as.integer(pred>0.5)  == cdata.te$diagnosis)
# lasso
x = as.matrix(cdata.tr[,-1])
y = as.integer(cdata.tr$diagnosis)
fit <- glmnet(x, y, family = "binomial", standardize = T)
# model selection by cv
fit_cv = cv.glmnet(x,as.integer(y), nfold = 5)
fit
x = as.matrix(cdata.tr[,-1])
y = as.integer(cdata.tr$diagnosis)
# model selection by cv
fit_cv = cv.glmnet(x,as.integer(y), nfold = 5)
i = which.min(fit_cv$cvm)
fit <- glmnet(x, y, family = "binomial", standardize = T,
lambda = fit_cv$lambda[i])
fit
predict(fit)
predx = as.matrix(cdata.te[,-1])
predy = as.matrix(cdata.te[,1])
predict(fit, predx)
drop(predict(fit, predx))
predict(fit, predx, type = 'response')
pred = predict(fit, predx, type = 'response')
mean(as.integer(pred>0.5)  == cdata.te$diagnosis)
v1 = v2 = c()
for (iter in 1:50)
{
idx = sample(1:n, trunc(n*0.7))
cdata.tr = cdata[idx,]
cdata.te = cdata[-idx,]
# forward selection
fit_init =glm(diagnosis~1,
data = cdata.tr, family = binomial())
fit_full =glm(diagnosis~.,
data = cdata.tr, family = binomial())
model_s = step(fit_init,
scope=list(lower=formula(fit_init),
upper=formula(fit_full)),
direction = 'forward')
pred = predict(model_s, cdata.te, type = 'response')
v1[iter] = mean(as.integer(pred>0.5)  == cdata.te$diagnosis)
# lasso
x = as.matrix(cdata.tr[,-1])
y = as.integer(cdata.tr$diagnosis)
# model selection by cv
fit_cv = cv.glmnet(x,as.integer(y), nfold = 5)
i = which.min(fit_cv$cvm)
fit <- glmnet(x, y, family = "binomial", standardize = T,
lambda = fit_cv$lambda[i])
predx = as.matrix(cdata.te[,-1])
predy = as.matrix(cdata.te[,1])
pred = predict(fit, predx, type = 'response')
v2[iter] = mean(as.integer(pred>0.5)  == cdata.te$diagnosis)
}
model_s = step(fit_init,
scope=list(lower=formula(fit_init),
upper=formula(fit_full)),
direction = 'forward',
trace = 0)
cat("iter::", iter, '\n')
boxplot(v1, v2)
boxplot(v1, v2, main = 'accuracy plot',
names = c('FS','Lasso'))
col = c("orange","lightblue")
boxplot(v1, v2, main = 'accuracy plot',
names = c('FS','Lasso'),
col = c("orange","lightblue"))
